{
  "uid": "ai-memory-classifier-health-v2",
  "title": "AI Memory Classifier Health",
  "tags": [
    "ai-memory",
    "classifier",
    "v2"
  ],
  "timezone": "browser",
  "schemaVersion": 39,
  "version": 7,
  "refresh": "30s",
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {
    "refresh_intervals": [
      "10s",
      "30s",
      "1m",
      "5m",
      "15m"
    ]
  },
  "templating": {
    "list": [
      {
        "name": "project",
        "type": "query",
        "datasource": {
          "type": "prometheus",
          "uid": "prometheus"
        },
        "query": "label_values(ai_memory_captures_total, project)",
        "refresh": 2,
        "includeAll": true,
        "allValue": ".*",
        "current": {
          "text": "All",
          "value": "$__all"
        }
      },
      {
        "name": "provider",
        "type": "custom",
        "options": [
          {
            "text": "ollama",
            "value": "ollama"
          },
          {
            "text": "openrouter",
            "value": "openrouter"
          },
          {
            "text": "openai",
            "value": "openai"
          },
          {
            "text": "claude",
            "value": "claude"
          }
        ],
        "multi": true,
        "includeAll": true,
        "current": {
          "text": "All",
          "value": [
            "$__all"
          ]
        },
        "allValue": ".*"
      },
      {
        "name": "type",
        "type": "custom",
        "options": [
          {
            "text": "implementation",
            "value": "implementation"
          },
          {
            "text": "error_fix",
            "value": "error_fix"
          },
          {
            "text": "refactor",
            "value": "refactor"
          },
          {
            "text": "file_pattern",
            "value": "file_pattern"
          },
          {
            "text": "rule",
            "value": "rule"
          },
          {
            "text": "guideline",
            "value": "guideline"
          },
          {
            "text": "port",
            "value": "port"
          },
          {
            "text": "naming",
            "value": "naming"
          },
          {
            "text": "structure",
            "value": "structure"
          },
          {
            "text": "decision",
            "value": "decision"
          },
          {
            "text": "session",
            "value": "session"
          },
          {
            "text": "blocker",
            "value": "blocker"
          },
          {
            "text": "preference",
            "value": "preference"
          },
          {
            "text": "user_message",
            "value": "user_message"
          },
          {
            "text": "agent_response",
            "value": "agent_response"
          }
        ],
        "multi": true,
        "includeAll": true,
        "current": {
          "text": "All",
          "value": [
            "$__all"
          ]
        },
        "allValue": ".*"
      }
    ]
  },
  "panels": [
    {
      "id": 100,
      "type": "text",
      "title": "",
      "gridPos": {
        "x": 0,
        "y": 0,
        "w": 24,
        "h": 6
      },
      "options": {
        "mode": "markdown",
        "content": "# AI Memory Classifier Health Dashboard\n\n**Purpose:** ML/AI classification monitoring - answering \"Is classification working?\", \"Which provider used?\", \"What types classified?\"\n\n**Audience:** ML Operators, Data Scientists\n\n**Providers:** Ollama (local) | OpenRouter (API) | OpenAI (API) | Claude (API)\n\n**Memory Types:** 15 types across 3 collections (code-patterns, conventions, discussions)\n\n**Template Variables:** Use dropdowns above to filter by provider or memory type"
      }
    },
    {
      "id": 1,
      "type": "stat",
      "title": "Total Classifications",
      "description": "**Metric:** `ai_memory_classifier_requests_total`\n**Measures:** Total classification requests sent to providers\n**Formula:** `sum(ai_memory_classifier_requests_total{provider=~\"$provider\", classified_type=~\"$type\"})`\n**Expected:** Growing as memories captured\n**Note:** Includes both success and error requests",
      "gridPos": {
        "x": 0,
        "y": 6,
        "w": 8,
        "h": 6
      },
      "targets": [
        {
          "expr": "sum(ai_memory_classifier_requests_total{provider=~\"$provider\", classified_type=~\"$type\"})",
          "refId": "A",
          "legendFormat": "Total Classifications"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 0,
          "noValue": "No data",
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#5794F2"
              }
            ]
          }
        }
      },
      "options": {
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        },
        "textMode": "value_and_name",
        "colorMode": "value",
        "graphMode": "area"
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 2,
      "type": "stat",
      "title": "Classification Success Rate",
      "description": "**Metric:** `ai_memory_classifier_requests_total`\n**Measures:** Percentage of successful classification requests\n**Formula:** `sum(ai_memory_classifier_requests_total{status=\"success\", ...}) / sum(ai_memory_classifier_requests_total{...}) * 100`\n**NFR:** >95% success rate\n**Thresholds:** Green >95% | Yellow 90-95% | Red <90%",
      "gridPos": {
        "x": 8,
        "y": 6,
        "w": 8,
        "h": 6
      },
      "targets": [
        {
          "expr": "sum(ai_memory_classifier_requests_total{status=\"success\", provider=~\"$provider\", classified_type=~\"$type\"}) / sum(ai_memory_classifier_requests_total{provider=~\"$provider\", classified_type=~\"$type\"}) * 100",
          "refId": "A",
          "legendFormat": "Success Rate"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "percent",
          "decimals": 1,
          "noValue": "No data",
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#F2495C"
              },
              {
                "value": 90,
                "color": "#FADE2A"
              },
              {
                "value": 95,
                "color": "#73BF69"
              }
            ]
          },
          "min": 0,
          "max": 100
        }
      },
      "options": {
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        },
        "textMode": "value_and_name",
        "colorMode": "value",
        "graphMode": "area"
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 3,
      "type": "stat",
      "title": "Queue Skipped (Already Classified)",
      "description": "**Metric:** `ai_memory_classifier_queue_processed_total{status=\"skipped\"}`\n**Measures:** Items skipped because already classified\n**Purpose:** Shows deduplication effectiveness\n**Expected:** Growing as queue processes duplicate requests\n**Note:** High skipped count = good deduplication",
      "gridPos": {
        "x": 16,
        "y": 6,
        "w": 8,
        "h": 6
      },
      "targets": [
        {
          "expr": "sum(ai_memory_classifier_queue_processed_total{status=\"skipped\"})",
          "refId": "A",
          "legendFormat": "Skipped"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 0,
          "noValue": "No data",
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#5794F2"
              }
            ]
          }
        }
      },
      "options": {
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        },
        "textMode": "value_and_name",
        "colorMode": "value",
        "graphMode": "area"
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 4,
      "type": "timeseries",
      "title": "Classification Requests by Type",
      "description": "**Metric:** `ai_memory_classifier_requests_total`\n**Groups by:** `classified_type` (decision, blocker, user_message, etc.)\n**Shows:** Distribution of memory types being classified\n**Expected:** user_message and agent_response most common",
      "gridPos": {
        "x": 0,
        "y": 12,
        "w": 24,
        "h": 10
      },
      "targets": [
        {
          "expr": "sum by (classified_type) (ai_memory_classifier_requests_total{provider=~\"$provider\", classified_type=~\"$type\"})",
          "refId": "A",
          "legendFormat": "{{classified_type}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "stepAfter",
            "lineWidth": 2,
            "fillOpacity": 10,
            "showPoints": "never",
            "spanNulls": false
          }
        }
      },
      "options": {
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        },
        "legend": {
          "displayMode": "table",
          "placement": "bottom",
          "calcs": [
            "lastNotNull",
            "max"
          ]
        }
      },
      "maxDataPoints": 5000,
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 5,
      "type": "timeseries",
      "title": "Provider Usage",
      "description": "**Metric:** `ai_memory_classifier_requests_total`\n**Groups by:** `provider` (ollama, openrouter, openai, claude)\n**Shows:** Which provider is handling classifications\n**Expected:** Primary provider handling most traffic",
      "gridPos": {
        "x": 0,
        "y": 12,
        "w": 24,
        "h": 10
      },
      "targets": [
        {
          "expr": "sum by (provider) (ai_memory_classifier_requests_total{provider=~\"$provider\", classified_type=~\"$type\"})",
          "refId": "A",
          "legendFormat": "{{provider}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "stepAfter",
            "lineWidth": 2,
            "fillOpacity": 10,
            "showPoints": "never",
            "spanNulls": false
          }
        }
      },
      "options": {
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        },
        "legend": {
          "displayMode": "table",
          "placement": "bottom",
          "calcs": [
            "lastNotNull",
            "max"
          ]
        }
      },
      "maxDataPoints": 5000,
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 6,
      "type": "timeseries",
      "title": "Classifier Fallbacks",
      "description": "**Metric:** `ai_memory_classifier_fallbacks_total`\n**Measures:** Provider fallback events (primary provider failed, switched to backup)\n**Formula:** `sum by (from_provider, to_provider) (ai_memory_classifier_fallbacks_total)`\n**Expected:** Rare - spikes indicate primary provider issues\n**Action:** If frequent, investigate primary provider health\n**See:** src/memory/classifier.py (fallback logic)",
      "gridPos": {
        "x": 0,
        "y": 22,
        "w": 24,
        "h": 8
      },
      "targets": [
        {
          "expr": "sum by (from_provider, to_provider) (ai_memory_classifier_fallbacks_total)",
          "refId": "A",
          "legendFormat": "{{from_provider}} \u2192 {{to_provider}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "stepAfter",
            "lineWidth": 2,
            "fillOpacity": 20,
            "showPoints": "auto",
            "spanNulls": false
          },
          "color": {
            "mode": "palette-classic"
          }
        }
      },
      "options": {
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        },
        "legend": {
          "displayMode": "table",
          "placement": "bottom",
          "calcs": [
            "lastNotNull",
            "sum"
          ]
        }
      },
      "maxDataPoints": 5000,
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 7,
      "type": "timeseries",
      "title": "Token Usage - Input Tokens by Provider",
      "description": "**Metric:** `ai_memory_classifier_tokens_total`\n**Measures:** Cumulative input tokens sent to classification providers\n**Formula:** `sum by (provider) (ai_memory_classifier_tokens_total{direction=\"input\", provider=~\"$provider\"})`\n**Purpose:** Cost tracking and provider usage monitoring\n**Expected:** Ollama (local) should be free, API providers incur costs\n**Note:** Pushgateway counter - NO rate() per BP-028\n**See:** BP-028 (Pushgateway), src/memory/classifier.py",
      "gridPos": {
        "x": 0,
        "y": 22,
        "w": 12,
        "h": 8
      },
      "targets": [
        {
          "expr": "sum by (provider) (ai_memory_classifier_tokens_total{direction=\"input\", provider=~\"$provider\"})",
          "refId": "A",
          "legendFormat": "{{provider}} (input)"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "stepAfter",
            "lineWidth": 2,
            "fillOpacity": 10,
            "showPoints": "never",
            "spanNulls": false
          },
          "color": {
            "mode": "palette-classic"
          }
        }
      },
      "options": {
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        },
        "legend": {
          "displayMode": "table",
          "placement": "bottom",
          "calcs": [
            "lastNotNull",
            "sum"
          ]
        }
      },
      "maxDataPoints": 5000,
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 8,
      "type": "timeseries",
      "title": "Token Usage - Output Tokens by Provider",
      "description": "**Metric:** `ai_memory_classifier_tokens_total`\n**Measures:** Cumulative output tokens received from classification providers\n**Formula:** `sum by (provider) (ai_memory_classifier_tokens_total{direction=\"output\", provider=~\"$provider\"})`\n**Purpose:** Cost tracking - output tokens may have different pricing\n**Expected:** Output tokens typically lower than input (classification results are concise)\n**Note:** Pushgateway counter - NO rate() per BP-028\n**See:** BP-028 (Pushgateway), src/memory/classifier.py",
      "gridPos": {
        "x": 12,
        "y": 22,
        "w": 12,
        "h": 8
      },
      "targets": [
        {
          "expr": "sum by (provider) (ai_memory_classifier_tokens_total{direction=\"output\", provider=~\"$provider\"})",
          "refId": "A",
          "legendFormat": "{{provider}} (output)"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "stepAfter",
            "lineWidth": 2,
            "fillOpacity": 10,
            "showPoints": "never",
            "spanNulls": false
          },
          "color": {
            "mode": "palette-classic"
          }
        }
      },
      "options": {
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        },
        "legend": {
          "displayMode": "table",
          "placement": "bottom",
          "calcs": [
            "lastNotNull",
            "sum"
          ]
        }
      },
      "maxDataPoints": 5000,
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 9,
      "type": "stat",
      "title": "Queue Size",
      "description": "**Metric:** `ai_memory_classifier_queue_size`\n**Measures:** Current number of items waiting for classification\n**Thresholds:** Green 0-10 | Yellow 10-50 | Red >50\n**Action:** High queue = provider bottleneck or failure",
      "gridPos": {
        "x": 0,
        "y": 30,
        "w": 6,
        "h": 6
      },
      "targets": [
        {
          "expr": "ai_memory_classifier_queue_size",
          "refId": "A",
          "legendFormat": "Queue Size"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 0,
          "noValue": "0",
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#73BF69"
              },
              {
                "value": 10,
                "color": "#FADE2A"
              },
              {
                "value": 50,
                "color": "#F2495C"
              }
            ]
          }
        }
      },
      "options": {
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        },
        "textMode": "value_and_name",
        "colorMode": "value",
        "graphMode": "none"
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 10,
      "type": "stat",
      "title": "Last Success",
      "description": "**Metric:** `ai_memory_classifier_last_success_timestamp`\n**Measures:** Unix timestamp of last successful classification\n**Purpose:** Alert if no recent classifications",
      "gridPos": {
        "x": 6,
        "y": 30,
        "w": 6,
        "h": 6
      },
      "targets": [
        {
          "expr": "time() - ai_memory_classifier_last_success_timestamp",
          "refId": "A",
          "legendFormat": "Seconds ago"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s",
          "decimals": 0,
          "noValue": "No data",
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#73BF69"
              },
              {
                "value": 300,
                "color": "#FADE2A"
              },
              {
                "value": 900,
                "color": "#F2495C"
              }
            ]
          }
        }
      },
      "options": {
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        },
        "textMode": "value_and_name",
        "colorMode": "value",
        "graphMode": "none"
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 11,
      "type": "timeseries",
      "title": "Classification Latency (p50/p95/p99)",
      "description": "**Metric:** `ai_memory_classifier_latency_seconds_bucket`\n**Measures:** Classification request duration by percentile\n**Target:** p95 < 2s for interactive experience\n**Thresholds:** Green <1s | Yellow 1-2s | Red >2s",
      "gridPos": {
        "x": 12,
        "y": 30,
        "w": 12,
        "h": 8
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum by (le) (rate(ai_memory_classifier_latency_seconds_bucket{provider=~\"$provider\"}[5m])))",
          "refId": "A",
          "legendFormat": "p50"
        },
        {
          "expr": "histogram_quantile(0.95, sum by (le) (rate(ai_memory_classifier_latency_seconds_bucket{provider=~\"$provider\"}[5m])))",
          "refId": "B",
          "legendFormat": "p95"
        },
        {
          "expr": "histogram_quantile(0.99, sum by (le) (rate(ai_memory_classifier_latency_seconds_bucket{provider=~\"$provider\"}[5m])))",
          "refId": "C",
          "legendFormat": "p99"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "fillOpacity": 10,
            "showPoints": "never",
            "spanNulls": false
          },
          "color": {
            "mode": "palette-classic"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#73BF69"
              },
              {
                "value": 1,
                "color": "#FADE2A"
              },
              {
                "value": 2,
                "color": "#F2495C"
              }
            ]
          }
        }
      },
      "options": {
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        },
        "legend": {
          "displayMode": "table",
          "placement": "bottom",
          "calcs": [
            "lastNotNull",
            "max"
          ]
        }
      },
      "maxDataPoints": 5000,
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 12,
      "type": "heatmap",
      "title": "Confidence Distribution by Type",
      "description": "**Metric:** `ai_memory_classifier_confidence_bucket`\n**Measures:** Distribution of classification confidence scores by type\n**Purpose:** Identify types that consistently get low confidence scores\n**Expected:** Most classifications >0.7 confidence",
      "gridPos": {
        "x": 0,
        "y": 38,
        "w": 24,
        "h": 8
      },
      "targets": [
        {
          "expr": "sum by (le, classified_type) (rate(ai_memory_classifier_confidence_bucket{classified_type=~\"$type\"}[5m]))",
          "refId": "A",
          "format": "heatmap",
          "legendFormat": "{{le}}"
        }
      ],
      "fieldConfig": {
        "defaults": {}
      },
      "options": {
        "calculate": false,
        "yAxis": {
          "axisPlacement": "left",
          "unit": "percentunit"
        },
        "color": {
          "scheme": "Spectral",
          "mode": "scheme"
        },
        "cellGap": 1,
        "tooltip": {
          "show": true
        }
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 13,
      "type": "timeseries",
      "title": "Batch Processing Duration",
      "description": "**Metric:** `ai_memory_classifier_batch_duration_seconds_bucket`\n**Measures:** Time to process classification batches\n**Purpose:** Monitor batch processing efficiency",
      "gridPos": {
        "x": 0,
        "y": 46,
        "w": 12,
        "h": 8
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum by (le) (rate(ai_memory_classifier_batch_duration_seconds_bucket[5m])))",
          "refId": "A",
          "legendFormat": "Batch p95"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "fillOpacity": 10,
            "showPoints": "never",
            "spanNulls": false
          },
          "color": {
            "mode": "palette-classic"
          }
        }
      },
      "options": {
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        },
        "legend": {
          "displayMode": "table",
          "placement": "bottom",
          "calcs": [
            "lastNotNull",
            "max"
          ]
        }
      },
      "maxDataPoints": 5000,
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 14,
      "type": "stat",
      "title": "Queue Dequeued Total",
      "description": "**Metric:** `ai_memory_classifier_queue_dequeued_total`\n**Measures:** Total items pulled from queue for processing\n**Expected:** Should match or exceed processed total",
      "gridPos": {
        "x": 12,
        "y": 46,
        "w": 6,
        "h": 6
      },
      "targets": [
        {
          "expr": "sum(ai_memory_classifier_queue_dequeued_total)",
          "refId": "A",
          "legendFormat": "Dequeued"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 0,
          "noValue": "No data",
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#5794F2"
              }
            ]
          }
        }
      },
      "options": {
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        },
        "textMode": "value_and_name",
        "colorMode": "value",
        "graphMode": "area"
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 15,
      "type": "stat",
      "title": "Queue Processed Total",
      "description": "**Metric:** `ai_memory_classifier_queue_processed_total`\n**Measures:** Total items successfully processed from queue\n**Status breakdown:** success, error, skipped",
      "gridPos": {
        "x": 18,
        "y": 46,
        "w": 6,
        "h": 6
      },
      "targets": [
        {
          "expr": "sum(ai_memory_classifier_queue_processed_total)",
          "refId": "A",
          "legendFormat": "Processed"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 0,
          "noValue": "No data",
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#5794F2"
              }
            ]
          }
        }
      },
      "options": {
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        },
        "textMode": "value_and_name",
        "colorMode": "value",
        "graphMode": "area"
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    }
  ],
  "editable": false,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "links": [],
  "liveNow": false,
  "style": "dark"
}