{
  "uid": "ai-memory-overview-v2",
  "title": "AI Memory System - Overview",
  "tags": [
    "ai-memory",
    "memory",
    "overview",
    "v2"
  ],
  "timezone": "browser",
  "schemaVersion": 39,
  "version": 9,
  "refresh": "30s",
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {
    "refresh_intervals": [
      "10s",
      "30s",
      "1m",
      "5m",
      "15m"
    ]
  },
  "templating": {
    "list": [
      {
        "name": "project",
        "type": "query",
        "datasource": {
          "type": "prometheus",
          "uid": "prometheus"
        },
        "query": "label_values(aimemory_captures_total, project)",
        "multi": true,
        "includeAll": true,
        "allValue": ".*",
        "current": {
          "text": "All",
          "value": "$__all"
        }
      },
      {
        "name": "hook",
        "type": "custom",
        "options": [
          {
            "text": "UserPromptSubmit",
            "value": "UserPromptSubmit"
          },
          {
            "text": "Stop",
            "value": "Stop"
          },
          {
            "text": "PreToolUse_FirstEdit",
            "value": "PreToolUse_FirstEdit"
          },
          {
            "text": "PostToolUse_ErrorDetection",
            "value": "PostToolUse_ErrorDetection"
          },
          {
            "text": "PreToolUse_BestPractices",
            "value": "PreToolUse_BestPractices"
          },
          {
            "text": "PreCompact",
            "value": "PreCompact"
          },
          {
            "text": "PreToolUse_NewFile",
            "value": "PreToolUse_NewFile"
          }
        ],
        "multi": true,
        "includeAll": true,
        "current": {
          "text": "All",
          "value": [
            "$__all"
          ]
        },
        "allValue": ".*"
      },
      {
        "name": "project_id",
        "type": "custom",
        "label": "Langfuse Project",
        "description": "Filter Langfuse deeplinks by project ID",
        "query": "All,dev-ai-memory",
        "current": {
          "selected": true,
          "text": "All",
          "value": "All"
        },
        "options": [
          {
            "selected": true,
            "text": "All",
            "value": "All"
          },
          {
            "selected": false,
            "text": "dev-ai-memory",
            "value": "dev-ai-memory"
          }
        ],
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "skipUrlSync": false
      }
    ]
  },
  "panels": [
    {
      "id": 100,
      "type": "text",
      "title": "",
      "gridPos": {
        "x": 0,
        "y": 0,
        "w": 24,
        "h": 5
      },
      "options": {
        "mode": "markdown",
        "content": "# AI Memory System - Overview Dashboard\n\n**Purpose:** Daily operational monitoring - answering \"How many memories captured?\", \"What's the success rate?\", \"What's the latency?\"\n\n**Audience:** Operators, Engineering Leads\n\n**Available Metrics:** `aimemory_captures_total`, `aimemory_hook_duration_seconds_bucket`, `aimemory_embedding_batch_duration_seconds_bucket`, `aimemory_embedding_realtime_duration_seconds_bucket`, `aimemory_retrieval_query_duration_seconds_bucket`, `aimemory_tokens_consumed_total`\n\n**Template Variables:** Use dropdowns above to filter by project or hook type"
      }
    },
    {
      "id": 1,
      "type": "stat",
      "title": "Total Captures",
      "description": "**Metric:** `aimemory_captures_total`\n**Measures:** Total number of memory capture attempts\n**Formula:** `sum(aimemory_captures_total)`\n**Thresholds:** Blue=info (growth expected)\n**See:** Core-Architecture-Principle-V2.md",
      "gridPos": {
        "x": 0,
        "y": 5,
        "w": 6,
        "h": 5
      },
      "targets": [
        {
          "expr": "sum(aimemory_captures_total{project=~\"$project\"})",
          "refId": "A",
          "legendFormat": "Total Captures"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 0,
          "noValue": "No data",
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#5794F2"
              }
            ]
          }
        }
      },
      "options": {
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        },
        "textMode": "value_and_name",
        "colorMode": "value",
        "graphMode": "area"
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 2,
      "type": "stat",
      "title": "Capture Success Rate",
      "description": "**Metric:** `aimemory_captures_total`\n**Measures:** Percentage of successful memory captures\n**Formula:** `sum(aimemory_captures_total{status=\"success\"}) / sum(aimemory_captures_total) * 100`\n**NFR:** >95% success rate (BP-022)\n**Thresholds:** Green >95% | Yellow 90-95% | Red <90%",
      "gridPos": {
        "x": 6,
        "y": 5,
        "w": 6,
        "h": 5
      },
      "targets": [
        {
          "expr": "sum(aimemory_captures_total{status=\"success\", project=~\"$project\"}) / sum(aimemory_captures_total{project=~\"$project\"}) * 100",
          "refId": "A",
          "legendFormat": "Success Rate"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "percent",
          "decimals": 1,
          "noValue": "No data",
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#F2495C"
              },
              {
                "value": 90,
                "color": "#FADE2A"
              },
              {
                "value": 95,
                "color": "#73BF69"
              }
            ]
          },
          "min": 0,
          "max": 100
        }
      },
      "options": {
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        },
        "textMode": "value_and_name",
        "colorMode": "value",
        "graphMode": "area"
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 3,
      "type": "stat",
      "title": "Embedding Success Rate",
      "description": "**Metric:** `aimemory_embedding_requests_total`\n**Measures:** Percentage of successful embedding requests\n**Formula:** `sum(aimemory_embedding_requests_total{status=\"success\"}) / sum(aimemory_embedding_requests_total) * 100`\n**Thresholds:** Green >95% | Yellow 90-95% | Red <90%",
      "gridPos": {
        "x": 12,
        "y": 5,
        "w": 6,
        "h": 5
      },
      "targets": [
        {
          "expr": "sum(aimemory_embedding_requests_total{status=\"success\"}) / sum(aimemory_embedding_requests_total) * 100",
          "refId": "A",
          "legendFormat": "Embedding Success Rate"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "percent",
          "decimals": 1,
          "noValue": "No data",
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#F2495C"
              },
              {
                "value": 90,
                "color": "#FADE2A"
              },
              {
                "value": 95,
                "color": "#73BF69"
              }
            ]
          },
          "min": 0,
          "max": 100
        }
      },
      "options": {
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        },
        "textMode": "value_and_name",
        "colorMode": "value",
        "graphMode": "area"
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 4,
      "type": "stat",
      "title": "Active Hooks",
      "description": "**Metric:** `aimemory_captures_total`\n**Measures:** Number of hooks that have captured at least one memory\n**Formula:** `count(count by (hook_type) (aimemory_captures_total))`\n**Expected:** Multiple hook types active",
      "gridPos": {
        "x": 18,
        "y": 5,
        "w": 6,
        "h": 5
      },
      "targets": [
        {
          "expr": "count(count by (hook_type) (aimemory_captures_total{project=~\"$project\"}))",
          "refId": "A",
          "legendFormat": "Active Hooks"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 0,
          "noValue": "No data",
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#5794F2"
              }
            ]
          }
        }
      },
      "options": {
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        },
        "textMode": "value_and_name",
        "colorMode": "value",
        "graphMode": "none"
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 5,
      "type": "timeseries",
      "title": "Memory Captures by Hook",
      "description": "**Metric:** `aimemory_captures_total`\n**Labels:** `[hook_type, status, project]`\n**Shows:** Capture attempts by hook type over time",
      "gridPos": {
        "x": 0,
        "y": 10,
        "w": 24,
        "h": 8
      },
      "targets": [
        {
          "expr": "sum by (hook_type, status) (aimemory_captures_total{hook_type=~\"$hook\", project=~\"$project\"})",
          "refId": "A",
          "legendFormat": "{{hook_type}} - {{status}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "stepAfter",
            "lineWidth": 2,
            "fillOpacity": 10,
            "showPoints": "never",
            "spanNulls": false
          }
        }
      },
      "options": {
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        },
        "legend": {
          "displayMode": "table",
          "placement": "bottom",
          "calcs": [
            "lastNotNull",
            "max"
          ]
        }
      },
      "maxDataPoints": 5000,
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 6,
      "type": "timeseries",
      "title": "Hook Latency (p50/p95/p99)",
      "description": "**Metric:** `aimemory_hook_duration_seconds_bucket`\n**Measures:** Hook execution time percentiles\n**NFR:** p95 < 500ms (BP-022)\n**Thresholds:** Green <500ms | Yellow 500ms-1s | Red >1s",
      "gridPos": {
        "x": 0,
        "y": 18,
        "w": 12,
        "h": 8
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum by (le) (aimemory_hook_duration_seconds_bucket))",
          "refId": "A",
          "legendFormat": "p50"
        },
        {
          "expr": "histogram_quantile(0.95, sum by (le) (aimemory_hook_duration_seconds_bucket))",
          "refId": "B",
          "legendFormat": "p95"
        },
        {
          "expr": "histogram_quantile(0.99, sum by (le) (aimemory_hook_duration_seconds_bucket))",
          "refId": "C",
          "legendFormat": "p99"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "fillOpacity": 10,
            "showPoints": "never"
          },
          "color": {
            "mode": "palette-classic"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#73BF69"
              },
              {
                "value": 0.5,
                "color": "#FADE2A"
              },
              {
                "value": 1.0,
                "color": "#F2495C"
              }
            ]
          }
        }
      },
      "options": {
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        },
        "legend": {
          "displayMode": "table",
          "placement": "bottom",
          "calcs": [
            "lastNotNull",
            "max"
          ]
        }
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 7,
      "type": "timeseries",
      "title": "Embedding Latency (p50/p95/p99)",
      "description": "**Metric:** `aimemory_embedding_batch_duration_seconds_bucket` + `aimemory_embedding_realtime_duration_seconds_bucket`\n**Measures:** Combined embedding generation time percentiles (batch + realtime)\n**NFR:** p95 < 2s (batch), <500ms (realtime) (BP-022)\n**Thresholds:** Green <2s | Yellow 2-5s | Red >5s",
      "gridPos": {
        "x": 12,
        "y": 18,
        "w": 12,
        "h": 8
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum by (le) (aimemory_embedding_batch_duration_seconds_bucket or aimemory_embedding_realtime_duration_seconds_bucket))",
          "refId": "A",
          "legendFormat": "p50"
        },
        {
          "expr": "histogram_quantile(0.95, sum by (le) (aimemory_embedding_batch_duration_seconds_bucket or aimemory_embedding_realtime_duration_seconds_bucket))",
          "refId": "B",
          "legendFormat": "p95"
        },
        {
          "expr": "histogram_quantile(0.99, sum by (le) (aimemory_embedding_batch_duration_seconds_bucket or aimemory_embedding_realtime_duration_seconds_bucket))",
          "refId": "C",
          "legendFormat": "p99"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "fillOpacity": 10,
            "showPoints": "never"
          },
          "color": {
            "mode": "palette-classic"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#73BF69"
              },
              {
                "value": 2.0,
                "color": "#FADE2A"
              },
              {
                "value": 5.0,
                "color": "#F2495C"
              }
            ]
          }
        }
      },
      "options": {
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        },
        "legend": {
          "displayMode": "table",
          "placement": "bottom",
          "calcs": [
            "lastNotNull",
            "max"
          ]
        }
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 8,
      "type": "timeseries",
      "title": "Search Latency (p50/p95/p99)",
      "description": "**Metric:** `aimemory_search_latency_bucket`\n**Measures:** Memory search time percentiles\n**NFR:** p95 < 100ms\n**Thresholds:** Green <100ms | Yellow 100-500ms | Red >500ms",
      "gridPos": {
        "x": 0,
        "y": 26,
        "w": 12,
        "h": 8
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum by (le) (aimemory_search_latency_bucket))",
          "refId": "A",
          "legendFormat": "p50"
        },
        {
          "expr": "histogram_quantile(0.95, sum by (le) (aimemory_search_latency_bucket))",
          "refId": "B",
          "legendFormat": "p95"
        },
        {
          "expr": "histogram_quantile(0.99, sum by (le) (aimemory_search_latency_bucket))",
          "refId": "C",
          "legendFormat": "p99"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "fillOpacity": 10,
            "showPoints": "never"
          },
          "color": {
            "mode": "palette-classic"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#73BF69"
              },
              {
                "value": 0.1,
                "color": "#FADE2A"
              },
              {
                "value": 0.5,
                "color": "#F2495C"
              }
            ]
          }
        }
      },
      "options": {
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        },
        "legend": {
          "displayMode": "table",
          "placement": "bottom",
          "calcs": [
            "lastNotNull",
            "max"
          ]
        }
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 9,
      "type": "timeseries",
      "title": "Token Consumption",
      "description": "**Metric:** `aimemory_tokens_consumed_total`\n**Measures:** Tokens consumed by operation and direction\n**Labels:** `[operation, direction, project]`\n**Shows:** Token usage trends for context injection",
      "gridPos": {
        "x": 12,
        "y": 26,
        "w": 12,
        "h": 8
      },
      "targets": [
        {
          "expr": "sum by (operation, direction) (aimemory_tokens_consumed_total{project=~\"$project\"})",
          "refId": "A",
          "legendFormat": "{{operation}} - {{direction}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "stepAfter",
            "lineWidth": 2,
            "fillOpacity": 10,
            "showPoints": "never",
            "spanNulls": false
          },
          "color": {
            "mode": "palette-classic"
          }
        }
      },
      "options": {
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        },
        "legend": {
          "displayMode": "table",
          "placement": "bottom",
          "calcs": [
            "lastNotNull",
            "sum"
          ]
        }
      },
      "maxDataPoints": 5000,
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 10,
      "type": "timeseries",
      "title": "Capture Failures",
      "description": "**Metric:** `aimemory_captures_total{status=\"error\"}`\n**Shows:** Failed capture attempts over time\n**Expected:** Flat line at zero (no failures)",
      "gridPos": {
        "x": 0,
        "y": 34,
        "w": 24,
        "h": 8
      },
      "targets": [
        {
          "expr": "sum by (hook_type) (aimemory_captures_total{status=\"error\", hook_type=~\"$hook\", project=~\"$project\"}) OR vector(0)",
          "refId": "A",
          "legendFormat": "{{hook_type}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "stepAfter",
            "lineWidth": 2,
            "fillOpacity": 20,
            "showPoints": "auto",
            "spanNulls": false
          },
          "color": {
            "mode": "fixed",
            "fixedColor": "red"
          },
          "noValue": "0",
          "min": 0
        }
      },
      "options": {
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        },
        "legend": {
          "displayMode": "table",
          "placement": "bottom",
          "calcs": [
            "lastNotNull",
            "sum"
          ]
        }
      },
      "maxDataPoints": 5000,
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 11,
      "type": "row",
      "title": "Classifier Queue (Future)",
      "gridPos": {
        "x": 0,
        "y": 42,
        "w": 24,
        "h": 1
      },
      "collapsed": false
    },
    {
      "id": 12,
      "type": "stat",
      "title": "Classifier Queue Size",
      "description": "**Metric:** `aimemory_classifier_queue_size`\n**Measures:** Items awaiting classification\n**Thresholds:** Green=0 | Yellow 1-5 | Red >5\n**Note:** Metric available after classifier worker T2 implementation",
      "gridPos": {
        "x": 0,
        "y": 43,
        "w": 8,
        "h": 5
      },
      "targets": [
        {
          "expr": "aimemory_classifier_queue_size OR vector(0)",
          "refId": "A",
          "legendFormat": "Queue Size"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 0,
          "noValue": "0",
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#73BF69"
              },
              {
                "value": 1,
                "color": "#FADE2A"
              },
              {
                "value": 5,
                "color": "#F2495C"
              }
            ]
          }
        }
      },
      "options": {
        "reduceOptions": {
          "values": false,
          "calcs": ["lastNotNull"]
        },
        "textMode": "value_and_name",
        "colorMode": "value",
        "graphMode": "area"
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 13,
      "type": "stat",
      "title": "Classifier Status",
      "description": "**Metric:** `aimemory_classifier_last_success_timestamp`\n**Measures:** Classifier worker liveness\n**Formula:** `time() - aimemory_classifier_last_success_timestamp < 300`\n**Value Mapping:** 1=UP (green), 0=DOWN (red)",
      "gridPos": {
        "x": 8,
        "y": 43,
        "w": 8,
        "h": 5
      },
      "targets": [
        {
          "expr": "time() - aimemory_classifier_last_success_timestamp < 300",
          "refId": "A",
          "legendFormat": "Classifier"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 0,
          "noValue": "DOWN",
          "mappings": [
            {
              "type": "value",
              "options": {
                "0": {
                  "text": "DOWN",
                  "color": "red"
                },
                "1": {
                  "text": "UP",
                  "color": "green"
                }
              }
            }
          ],
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#F2495C"
              },
              {
                "value": 1,
                "color": "#73BF69"
              }
            ]
          }
        }
      },
      "options": {
        "reduceOptions": {
          "values": false,
          "calcs": ["lastNotNull"]
        },
        "textMode": "value",
        "colorMode": "background"
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 14,
      "type": "stat",
      "title": "Classifier Requests",
      "description": "**Metric:** `aimemory_classifier_requests_total`\n**Measures:** Total classification requests\n**Labels:** `[provider, status, classified_type]`\n**Note:** Metric available after classifier worker T2 implementation",
      "gridPos": {
        "x": 16,
        "y": 43,
        "w": 8,
        "h": 5
      },
      "targets": [
        {
          "expr": "sum(aimemory_classifier_requests_total) OR vector(0)",
          "refId": "A",
          "legendFormat": "Total Requests"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 0,
          "noValue": "0",
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "#5794F2"
              }
            ]
          }
        }
      },
      "options": {
        "reduceOptions": {
          "values": false,
          "calcs": ["lastNotNull"]
        },
        "textMode": "value_and_name",
        "colorMode": "value",
        "graphMode": "area"
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "id": 15,
      "type": "timeseries",
      "title": "Classifier Latency (p50/p95/p99)",
      "description": "**Metric:** `aimemory_classifier_latency_seconds_bucket`\n**Measures:** Classification time percentiles\n**Note:** Metric available after classifier worker T2 implementation",
      "gridPos": {
        "x": 0,
        "y": 48,
        "w": 24,
        "h": 8
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum by (le) (aimemory_classifier_latency_seconds_bucket))",
          "refId": "A",
          "legendFormat": "p50"
        },
        {
          "expr": "histogram_quantile(0.95, sum by (le) (aimemory_classifier_latency_seconds_bucket))",
          "refId": "B",
          "legendFormat": "p95"
        },
        {
          "expr": "histogram_quantile(0.99, sum by (le) (aimemory_classifier_latency_seconds_bucket))",
          "refId": "C",
          "legendFormat": "p99"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "fillOpacity": 10,
            "showPoints": "never"
          },
          "color": {
            "mode": "palette-classic"
          },
          "noValue": "No data (classifier T2 pending)"
        }
      },
      "options": {
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        },
        "legend": {
          "displayMode": "table",
          "placement": "bottom",
          "calcs": [
            "lastNotNull",
            "max"
          ]
        }
      },
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      }
    },
    {
      "type": "row",
      "title": "LLM Observability",
      "collapsed": true,
      "gridPos": { "h": 1, "w": 24, "x": 0, "y": 56 },
      "id": 101,
      "panels": [
        {
          "type": "text",
          "title": "Langfuse Traces",
          "id": 102,
          "gridPos": { "h": 4, "w": 8, "x": 0, "y": 57 },
          "options": {
            "mode": "markdown",
            "content": "### [Open Langfuse Traces](http://localhost:23100/traces)\n\nView all LLM traces captured by the AI Memory pipeline.\n\n- Session-level traces from Claude Code Stop hook\n- Pipeline step spans (capture → embed → store → classify)"
          }
        },
        {
          "type": "text",
          "title": "Langfuse Sessions",
          "id": 103,
          "gridPos": { "h": 4, "w": 8, "x": 8, "y": 57 },
          "options": {
            "mode": "markdown",
            "content": "### [Open Langfuse Sessions](http://localhost:23100/sessions)\n\nView conversation sessions grouped by Claude Code session ID.\n\n- Parzival sessions tagged with `agent_id=parzival`\n- Developer sessions without agent tag"
          }
        },
        {
          "type": "text",
          "title": "Langfuse — Filter by Project",
          "id": 104,
          "gridPos": { "h": 4, "w": 8, "x": 16, "y": 57 },
          "options": {
            "mode": "markdown",
            "content": "### Filter Traces by Project\n\nSelect a specific project from the **Langfuse Project** dropdown above, then use this link:\n\n[View Project Traces](http://localhost:23100/traces?filter=metadata.project_id%3D${project_id})\n\n> **Note:** The link above filters by the selected project. \"All\" is not a valid Langfuse filter — select a specific project name.\n\n**Quick filters:**\n- [Parzival Sessions](http://localhost:23100/traces?filter=metadata.agent_id%3Dparzival)\n- [Classifier Traces](http://localhost:23100/traces?filter=metadata.span_name%3D9_classify)"
          }
        },
        {
          "type": "text",
          "title": "Langfuse — Generations & Token Usage",
          "id": 105,
          "gridPos": { "h": 4, "w": 24, "x": 0, "y": 61 },
          "options": {
            "mode": "markdown",
            "content": "### [Open Langfuse Generations](http://localhost:23100/generations)\n\nView token usage and LLM generation costs tracked by the AI Memory pipeline.\n\n- **Generations**: Individual LLM calls with model, input/output tokens, cost\n- **Token Usage**: Aggregate token consumption per session and pipeline step\n- **Cost Tracking**: Per-model pricing (configure in Langfuse Settings → Models)\n\n**Quick links:**\n- [All Generations](http://localhost:23100/generations)\n- [Cost Dashboard](http://localhost:23100/project/default/dashboard)"
          }
        }
      ]
    }
  ],
  "editable": false,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "links": [],
  "liveNow": false,
  "style": "dark"
}
