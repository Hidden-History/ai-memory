name: ai-memory

services:
  qdrant:
    image: qdrant/qdrant:v1.16.3
    container_name: ${AI_MEMORY_CONTAINER_PREFIX:-ai-memory}-qdrant
    ports:
      - "127.0.0.1:${QDRANT_PORT:-26350}:6333"
      - "127.0.0.1:${QDRANT_GRPC_PORT:-26351}:6334"
    volumes:
      - qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__LOG_LEVEL=${QDRANT_LOG_LEVEL:-INFO}
      # API Key Authentication (BP-040) - Requires TLS for production
      # For localhost-only development, API key provides basic access control
      - QDRANT__SERVICE__API_KEY=${QDRANT_API_KEY}
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "bash -c 'echo > /dev/tcp/localhost/6333'"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  embedding:
    build:
      context: ..
      dockerfile: docker/embedding/Dockerfile
    container_name: ${AI_MEMORY_CONTAINER_PREFIX:-ai-memory}-embedding
    ports:
      - "127.0.0.1:${EMBEDDING_PORT:-28080}:8080"
    volumes:
      # fastembed stores models in ~/.cache/fastembed, mount entire cache dir
      - embedding_cache:/home/embedding/.cache
    environment:
      - MODEL_NAME=jinaai/jina-embeddings-v2-base-en
      - VECTOR_DIMENSIONS=768
      - LOG_LEVEL=${BMAD_LOG_LEVEL:-INFO}
      # Set fastembed cache to persistent volume location
      - FASTEMBED_CACHE_PATH=/home/embedding/.cache/fastembed
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 15
      start_period: 300s  # BUG-040: Increased for first-time model download (~500MB). Total wait: 300s + 30s*15 = 750s (12.5 min)
    deploy:
      resources:
        limits:
          memory: 4G

  monitoring-api:
    build:
      context: ..
      dockerfile: monitoring/Dockerfile
    container_name: ${AI_MEMORY_CONTAINER_PREFIX:-ai-memory}-monitoring-api
    profiles: ["testing", "monitoring"]
    ports:
      - "127.0.0.1:28000:8000"
    environment:
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - QDRANT_API_KEY=${QDRANT_API_KEY}
      - VECTOR_DIMENSIONS=768
    depends_on:
      qdrant:
        condition: service_healthy
    restart: unless-stopped
    # Security hardening (2026 best practices)
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    read_only: true
    tmpfs:
      - /tmp:rw,noexec,nosuid
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; exit(0 if httpx.get('http://localhost:8000/health', timeout=5).status_code == 200 else 1)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  prometheus:
    image: prom/prometheus:v2.55.1
    container_name: ${AI_MEMORY_CONTAINER_PREFIX:-ai-memory}-prometheus
    profiles: ["monitoring"]
    ports:
      - "127.0.0.1:29090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/web.yml:/etc/prometheus/web.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--web.config.file=/etc/prometheus/web.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    restart: unless-stopped
    # Security hardening (2026 best practices)
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    networks:
      - default
    # BP-040: Healthcheck with basic auth via Authorization header
    # Generate new hash: echo "$(htpasswd -nBC 10 admin)" | base64
    # Then set PROMETHEUS_BASIC_AUTH_HEADER in .env (format: "Basic <base64>")
    # Note: For production, use external monitoring (Grafana checks, monitoring-api)
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "--header=Authorization: ${PROMETHEUS_BASIC_AUTH_HEADER:-Basic REPLACE_WITH_BASE64_CREDENTIALS}", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  pushgateway:
    image: prom/pushgateway:v1.9.0
    container_name: ${AI_MEMORY_CONTAINER_PREFIX:-ai-memory}-pushgateway
    profiles: ["monitoring"]
    # Enable persistence to retain metrics across restarts (BP-028)
    command:
      - "--persistence.file=/data/pushgateway.pf"
      - "--persistence.interval=5m"
    ports:
      - "127.0.0.1:29091:9091"
    restart: unless-stopped
    volumes:
      - pushgateway_data:/data
    # Security hardening (2026 best practices)
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    networks:
      - default
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9091/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  grafana:
    image: grafana/grafana:12.0.0
    container_name: ${AI_MEMORY_CONTAINER_PREFIX:-ai-memory}-grafana
    profiles: ["monitoring"]
    ports:
      - "127.0.0.1:23000:3000"
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/etc/grafana/dashboards:ro
      - grafana_data:/var/lib/grafana
    environment:
      # Admin Credentials (BP-040) - Only applies on FIRST LAUNCH
      # To change existing password: docker exec -it ai-memory-grafana grafana-cli admin reset-admin-password <new_password>
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      # Prometheus datasource auth (BP-040) - used by provisioning file env substitution
      - PROMETHEUS_ADMIN_PASSWORD=${PROMETHEUS_ADMIN_PASSWORD}
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Viewer
      - GF_SERVER_ROOT_URL=http://localhost:23000
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      # Session configuration (prevent frequent re-login)
      - GF_AUTH_LOGIN_COOKIE_NAME=grafana_session
      - GF_AUTH_LOGIN_MAXIMUM_INACTIVE_LIFETIME_DURATION=7d
      - GF_AUTH_LOGIN_MAXIMUM_LIFETIME_DURATION=30d
      # Security hardening (2026 best practices)
      - GF_SECURITY_CSRF_ALWAYS_CHECK=true
      - GF_SNAPSHOTS_EXTERNAL_ENABLED=false
    # Security hardening (2026 best practices)
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    depends_on:
      prometheus:
        condition: service_started
    restart: unless-stopped
    networks:
      - default
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  # NOTE: grafana-datasource-init removed - credentials now injected via
  # environment variable substitution in provisioning file (BP-040, Grafana 10+)

  streamlit:
    build:
      context: ./streamlit
      dockerfile: Dockerfile
    container_name: ${AI_MEMORY_CONTAINER_PREFIX:-ai-memory}-streamlit
    profiles: ["monitoring"]
    # Authentication: Deferred to Phase 2 (TECH-DEBT-076)
    # Requires streamlit-authenticator library or OIDC (BP-040 Section 4)
    ports:
      - "127.0.0.1:28501:8501"
    volumes:
      # Use AI_MEMORY_INSTALL_DIR for project-specific logs (multi-project support)
      # logs: read-write (hooks need write access for activity logging)
      # queue: read-only (Streamlit only reads pending operations)
      # QUEUE-UNIFY: All queues now use unified pending_queue.jsonl in /app/queue
      - ${AI_MEMORY_INSTALL_DIR:-${HOME}/.ai-memory}/logs:/app/logs
      - ${AI_MEMORY_INSTALL_DIR:-${HOME}/.ai-memory}/queue:/app/queue:ro
      # Mount src/ for memory.models import (DRY - single source of truth for types)
      - ../src:/app/src:ro
    environment:
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - QDRANT_API_KEY=${QDRANT_API_KEY}
      - QDRANT_USE_HTTPS=${QDRANT_USE_HTTPS:-false}
      - QDRANT_EXTERNAL_PORT=26350
      - EMBEDDING_SERVICE_URL=http://embedding:8080
      # Pass install dir for activity log path
      - AI_MEMORY_INSTALL_DIR=/app
    depends_on:
      qdrant:
        condition: service_healthy
      embedding:
        condition: service_healthy
    restart: on-failure:3
    # Security hardening (2026 best practices)
    # Note: read_only disabled to allow Streamlit machine ID creation
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    tmpfs:
      - /tmp:rw,noexec,nosuid,size=50m
    networks:
      - default
    # Resource limits to prevent memory exhaustion
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
    # Log rotation configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  classifier-worker:
    build:
      context: ..
      dockerfile: docker/Dockerfile.worker
    container_name: ${AI_MEMORY_CONTAINER_PREFIX:-ai-memory}-classifier-worker
    profiles: ["monitoring"]  # Only runs with monitoring profile
    restart: unless-stopped
    environment:
      # Qdrant connection
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - QDRANT_API_KEY=${QDRANT_API_KEY}
      - PUSHGATEWAY_URL=pushgateway:9091
      - AI_MEMORY_QUEUE_DIR=/app/queue
      # Classifier configuration
      - MEMORY_CLASSIFIER_ENABLED=${MEMORY_CLASSIFIER_ENABLED:-true}
      - MEMORY_CLASSIFIER_PRIMARY_PROVIDER=${MEMORY_CLASSIFIER_PRIMARY_PROVIDER:-ollama}
      - MEMORY_CLASSIFIER_FALLBACK_PROVIDERS=${MEMORY_CLASSIFIER_FALLBACK_PROVIDERS:-}
      - MEMORY_CLASSIFIER_CONFIDENCE_THRESHOLD=${MEMORY_CLASSIFIER_CONFIDENCE_THRESHOLD:-0.7}
      - MEMORY_CLASSIFIER_TIMEOUT=${MEMORY_CLASSIFIER_TIMEOUT:-30}
      # Ollama
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-sam860/LFM2:2.6b}
      # OpenRouter
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY:-}
      - OPENROUTER_MODEL=${OPENROUTER_MODEL:-google/gemma-2-9b-it:free}
      # Anthropic Claude
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - ANTHROPIC_MODEL=${ANTHROPIC_MODEL:-claude-3-haiku-20240307}
      # OpenAI
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
    volumes:
      - ../src:/app/src:ro
      - ../scripts:/app/scripts:ro
      - ${AI_MEMORY_QUEUE_DIR:-~/.ai-memory/queue}:/app/queue
    depends_on:
      qdrant:
        condition: service_healthy
    # Run as host user for queue file access (bind mount permissions)
    user: "${UID:-1000}:${GID:-1000}"
    stop_grace_period: 30s
    # Security hardening (2025 best practices)
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    read_only: true
    tmpfs:
      - /tmp:rw,noexec,nosuid,size=50m
    networks:
      - default  # Internal network - classifier communicates with qdrant/pushgateway only
    # Resource limits to prevent exhaustion
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 256M
    # Log rotation configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD", "python3", "-c", "from pathlib import Path; exit(0 if Path('/tmp/worker.health').exists() else 1)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s  # F2/F9: Allow time for Python startup, logger init, and first health file creation (typically <5s, buffer for slow systems)

volumes:
  qdrant_storage:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  embedding_cache:
    driver: local
  pushgateway_data:
    driver: local
  classifier_queue:
    driver: local
