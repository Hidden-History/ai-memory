# ============================================
# AI-MEMORY DOCKER ENVIRONMENT CONFIGURATION
# ============================================
#
# QUICK SETUP:
#   1. Copy this file: cp .env.example .env
#   2. Generate all secrets (run each command and paste result):
#
#      GRAFANA_SECRET_KEY:
#        python3 -c "import secrets; print(secrets.token_urlsafe(32))"
#
#      GRAFANA_ADMIN_PASSWORD:
#        python3 -c "import secrets; print(secrets.token_urlsafe(16))"
#
#      PROMETHEUS_ADMIN_PASSWORD:
#        python3 -c "import secrets; print(secrets.token_urlsafe(16))"
#
#      PROMETHEUS_BASIC_AUTH_HEADER (after setting password above):
#        echo -n "admin:YOUR_PROMETHEUS_PASSWORD" | base64
#        # Then prefix with "Basic " e.g., Basic YWRtaW46cGFzc3dvcmQ=
#
#      QDRANT_API_KEY:
#        python3 -c "import secrets; print(secrets.token_urlsafe(32))"
#
#   3. Update prometheus/web.yml with bcrypt hash of PROMETHEUS_ADMIN_PASSWORD
#   4. Start services: docker compose --profile monitoring up -d
#
# IMPORTANT SYNC REQUIREMENTS:
#   - PROMETHEUS_ADMIN_PASSWORD ↔ prometheus/web.yml bcrypt hash
#   - PROMETHEUS_ADMIN_PASSWORD ↔ PROMETHEUS_BASIC_AUTH_HEADER
#   - If ANY of these desync, Prometheus auth will fail silently
#
# ============================================

# =============================================================================
# CONTAINER CONFIGURATION
# =============================================================================
# Container name prefix (for running multiple stacks)
AI_MEMORY_CONTAINER_PREFIX=ai-memory

# Qdrant HTTP API Port (default: 26350)
QDRANT_PORT=26350

# Qdrant gRPC Port (default: 26351)
QDRANT_GRPC_PORT=26351

# Qdrant Log Level (default: INFO)
# Options: TRACE, DEBUG, INFO, WARN, ERROR
QDRANT_LOG_LEVEL=INFO

# Embedding Service Port (default: 28080)
EMBEDDING_PORT=28080

# BMAD Log Level (default: INFO)
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
BMAD_LOG_LEVEL=INFO

# AI Memory Installation Directory (for volume mounts)
# Must match the project installation path
AI_MEMORY_INSTALL_DIR=/path/to/your/project

# ============================================
# GRAFANA CONFIGURATION
# ============================================
# CRITICAL: Never commit real credentials to git. Copy this to .env and customize.
# For production, migrate to Docker Secrets (see BP-040 documentation).

# Username for Grafana admin user (default: admin)
GRAFANA_ADMIN_USER=admin

# Password for Grafana admin user (set strong password)
# Generate: python3 -c "import secrets; print(secrets.token_urlsafe(16))"
# NOTE: Only applies on FIRST LAUNCH. To change existing:
#   docker exec -it memory-grafana grafana-cli admin reset-admin-password <new_password>
GRAFANA_ADMIN_PASSWORD=

# Grafana cookie encryption key (TECH-DEBT-103/127)
# Used for encrypting session cookies and CSRF tokens. Required for secure multi-instance deployments.
# Generate (32+ chars): python3 -c "import secrets; print(secrets.token_urlsafe(32))"
GRAFANA_SECRET_KEY=

# ============================================
# PROMETHEUS AUTHENTICATION
# ============================================
# IMPORTANT: If you change PROMETHEUS_ADMIN_PASSWORD, you MUST also:
#   1. Regenerate the bcrypt hash in docker/prometheus/web.yml
#   2. Regenerate PROMETHEUS_BASIC_AUTH_HEADER below
#
# To regenerate bcrypt hash:
#   python3 -c "import bcrypt; print(bcrypt.hashpw(b'YOUR_NEW_PASSWORD', bcrypt.gensalt(rounds=12)).decode())"
#
# Then update docker/prometheus/web.yml:
#   basic_auth_users:
#     admin: <paste-new-hash-here>
#
# Generate with: python3 -c "import secrets; print(secrets.token_urlsafe(16))"
PROMETHEUS_ADMIN_PASSWORD=

# Base64-encoded "admin:password" for Prometheus basic auth
# MUST match PROMETHEUS_ADMIN_PASSWORD above
#
# To generate (replace YOUR_PASSWORD with actual password):
#   echo -n "admin:YOUR_PASSWORD" | base64
#
# Or with Python:
#   python3 -c "import base64; print('Basic ' + base64.b64encode(b'admin:YOUR_PASSWORD').decode())"
#
# Format: Basic <base64-encoded-credentials>
PROMETHEUS_BASIC_AUTH_HEADER=

# ============================================
# QDRANT AUTHENTICATION
# ============================================
# Primary API key for read/write operations (required)
# Generate with: python3 -c "import secrets; print(secrets.token_urlsafe(32))"
QDRANT_API_KEY=

# Read-only API key for monitoring and dashboards (optional)
# Purpose: Allows Prometheus/Grafana to scrape Qdrant metrics without write access
# Future use: Will be used for read-only API endpoints and monitoring integrations
# Generate with: python3 -c "import secrets; print(secrets.token_urlsafe(32))"
QDRANT_READ_ONLY_API_KEY=

# ============================================
# OTHER CONFIGURATION
# ============================================
# IMPORTANT Security Notes:
# 1. Qdrant API keys require TLS for production use (we're localhost-only for dev)
# 2. After setting PROMETHEUS_ADMIN_PASSWORD, update prometheus/web.yml with bcrypt hash
# 3. Bind all ports to 127.0.0.1 (already configured) unless using internal Docker networks
# 4. For production: Use Docker Secrets instead of environment variables

# Streamlit Authentication
# Note: Deferred to Phase 2 - requires authentication library installation
# Will implement: streamlit-authenticator or OIDC (BP-040 Section 4)

# =============================================================================
# LLM MEMORY CLASSIFIER CONFIGURATION
# =============================================================================
# Enable/disable memory type classification
MEMORY_CLASSIFIER_ENABLED=true

# =============================================================================
# PROVIDER SELECTION
# =============================================================================
# Primary provider: ollama | openrouter | claude | openai
MEMORY_CLASSIFIER_PRIMARY_PROVIDER=ollama

# Fallback providers (comma-separated)
# Example: openrouter,claude,openai
MEMORY_CLASSIFIER_FALLBACK_PROVIDERS=openrouter

# =============================================================================
# OLLAMA (Local LLM - Free)
# =============================================================================
# URL for Ollama API:
#   - For Docker Desktop (Windows/Mac): http://host.docker.internal:11434 (recommended)
#   - For native Linux Docker: http://172.17.0.1:11434 (Docker bridge gateway)
#   - For WSL without Docker: auto (auto-detects Windows host IP)
#   - For native Linux without Docker: http://localhost:11434
# NOTE: "auto" detection may not work reliably inside Docker containers.
OLLAMA_BASE_URL=http://host.docker.internal:11434

# Recommended models:
#   - sam860/LFM2:2.6b (default, fast)
#   - llama3.2:3b (good quality)
#   - phi3:mini (good reasoning)
OLLAMA_MODEL=sam860/LFM2:2.6b

# =============================================================================
# OPENROUTER (Cloud LLM - Pay per use)
# =============================================================================
# Get your API key at: https://openrouter.ai/keys
OPENROUTER_API_KEY=

# Recommended models:
#   - google/gemma-2-9b-it:free (free tier)
#   - mistralai/mistral-7b-instruct (cheap)
#   - anthropic/claude-3-haiku (high quality)
OPENROUTER_MODEL=google/gemma-2-9b-it:free

# =============================================================================
# ANTHROPIC CLAUDE (Cloud LLM - High quality)
# =============================================================================
# Get your API key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# Recommended models:
#   - claude-3-haiku-20240307 (fastest)
#   - claude-3-5-sonnet-20241022 (best quality/cost)
ANTHROPIC_MODEL=claude-3-haiku-20240307

# =============================================================================
# OPENAI (Cloud LLM)
# =============================================================================
# Get your API key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Recommended models:
#   - gpt-4o-mini (cheapest, good quality)
#   - gpt-4o (best quality)
OPENAI_MODEL=gpt-4o-mini

# =============================================================================
# CLASSIFICATION THRESHOLDS
# =============================================================================
MEMORY_CLASSIFIER_CONFIDENCE_THRESHOLD=0.7
MEMORY_CLASSIFIER_RULE_CONFIDENCE=0.85
MEMORY_CLASSIFIER_MIN_CONTENT_LENGTH=20

# =============================================================================
# PERFORMANCE SETTINGS
# =============================================================================
MEMORY_CLASSIFIER_TIMEOUT=30
MEMORY_CLASSIFIER_MAX_TOKENS=500
MEMORY_CLASSIFIER_MAX_INPUT_CHARS=4000
