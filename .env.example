# .env.example - AI Memory Module Configuration
# Copy to .env and modify as needed
# Source: Story 7.4 - Environment Variable Configuration

# =============================================================================
# Core Thresholds (FR42)
# =============================================================================

# Minimum similarity score for retrieval (0.0-1.0)
# Lower = more results, potentially less relevant
# Default: 0.7
SIMILARITY_THRESHOLD=0.7

# Similarity threshold for deduplication (0.80-0.99)
# Higher = stricter dedup, fewer similar memories stored
# Default: 0.95
DEDUP_THRESHOLD=0.95

# Maximum memories to retrieve per session (1-50)
# Default: 5
MAX_RETRIEVALS=5

# Token budget for context injection (100-100000)
# Controls how much context is sent to Claude
# Default: 4000 (increased per BP-039 Section 3: "Target 50% context window utilization")
TOKEN_BUDGET=4000

# =============================================================================
# Service Configuration
# =============================================================================

# Qdrant connection
# Default: localhost:26350 (Story 1.1)
QDRANT_HOST=localhost
QDRANT_PORT=26350

# Optional Qdrant API key for authentication
# Leave empty for local development
# QDRANT_API_KEY=

# Embedding service
# Default: localhost:28080 (DEC-004)
EMBEDDING_HOST=localhost
EMBEDDING_PORT=28080

# Monitoring API
# Default: localhost:28000
MONITORING_HOST=localhost
MONITORING_PORT=28000

# =============================================================================
# Grafana & Prometheus Configuration (BP-040)
# =============================================================================

# Grafana session security (REQUIRED for production)
# Generate with: openssl rand -hex 32
# GRAFANA_SECRET_KEY=your-secret-key-here

# Prometheus basic auth header for healthcheck and Grafana datasource
# Generate base64: echo -n "admin:password" | base64
# PROMETHEUS_BASIC_AUTH_HEADER=Basic YWRtaW46cGFzc3dvcmQ=

# =============================================================================
# Logging & Monitoring
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Default: INFO
LOG_LEVEL=INFO

# Log format: json (production), text (development)
# Default: json
LOG_FORMAT=json

# Collection size warning threshold
# Default: 10000
COLLECTION_SIZE_WARNING=10000

# Collection size critical threshold
# Default: 50000
COLLECTION_SIZE_CRITICAL=50000

# =============================================================================
# Pushgateway Configuration (TECH-DEBT-008)
# =============================================================================

# Enable pushgateway metrics for short-lived hook processes
# Set to false to disable metrics pushing
# Default: true
PUSHGATEWAY_ENABLED=true

# Pushgateway URL for metrics push
# Used by hooks to push execution metrics
# Default: localhost:29091
PUSHGATEWAY_URL=localhost:29091

# =============================================================================
# Paths
# =============================================================================

# Installation directory
# Default: ~/.ai-memory
# INSTALL_DIR=$HOME/.ai-memory

# Queue file for pending operations
# Default: ~/.claude-memory/pending_queue.jsonl
# QUEUE_PATH=$HOME/.claude-memory/pending_queue.jsonl

# Session logs
# Default: ~/.claude-memory/sessions.jsonl
# SESSION_LOG_PATH=$HOME/.claude-memory/sessions.jsonl

# =============================================================================
# MEMORY CLASSIFIER CONFIGURATION (TECH-DEBT-069)
# =============================================================================

# Enable/disable LLM-based classification
# Default: true
MEMORY_CLASSIFIER_ENABLED=true

# Warm up model on startup (pre-load for faster first classification)
# Default: true
MEMORY_CLASSIFIER_WARM_UP=true

# Run classification asynchronously in background
# Default: true
MEMORY_CLASSIFIER_ASYNC=true

# Queue failed classifications for retry
# Default: true
MEMORY_CLASSIFIER_QUEUE_ON_FAILURE=true

# --- Provider Selection ---
# Primary provider: ollama (free, local), openrouter (cheap), or claude (reliable)
# Default: ollama
MEMORY_CLASSIFIER_PRIMARY_PROVIDER=ollama

# Fallback providers (comma-separated)
# Default: openrouter,claude
MEMORY_CLASSIFIER_FALLBACK_PROVIDERS=openrouter,claude

# --- Thresholds ---
# Minimum confidence to change memory type (0.0-1.0)
# Default: 0.7
MEMORY_CLASSIFIER_CONFIDENCE_THRESHOLD=0.7

# Minimum confidence for rule-based classification to skip LLM (0.0-1.0)
# Default: 0.85
MEMORY_CLASSIFIER_RULE_CONFIDENCE=0.85

# Minimum content length to classify (characters)
# Default: 20
MEMORY_CLASSIFIER_MIN_CONTENT_LENGTH=20

# --- Performance ---
# Timeout per provider attempt (seconds)
# Default: 10
MEMORY_CLASSIFIER_TIMEOUT=10

# Maximum output tokens from LLM
# Default: 500
MEMORY_CLASSIFIER_MAX_TOKENS=500

# Maximum input characters (longer content is truncated)
# Default: 4000
MEMORY_CLASSIFIER_MAX_INPUT_CHARS=4000

# Rate limit (max classifications per minute)
# Default: 60
MEMORY_CLASSIFIER_RATE_LIMIT=60

# --- Ollama Configuration (free, local) ---
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# --- OpenRouter Configuration (cheap fallback) ---
# Get API key from: https://openrouter.ai/keys
# OPENROUTER_API_KEY=sk-or-v1-...
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
OPENROUTER_MODEL=anthropic/claude-3-haiku

# --- Claude/Anthropic Configuration (reliable fallback) ---
# Uses existing ANTHROPIC_API_KEY if already set
# ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-3-5-haiku-20241022

# ============================================================
# v2.0.6 Settings — Intent + Git History + Semantic Decay
# ============================================================

# --- Decay Scoring (Foundation) ---
DECAY_ENABLED=true
DECAY_SEMANTIC_WEIGHT=0.7
DECAY_HALF_LIFE_CODE_PATTERNS=14
DECAY_HALF_LIFE_DISCUSSIONS=21
DECAY_HALF_LIFE_CONVENTIONS=60
DECAY_HALF_LIFE_JIRA_DATA=30
# DECAY_MIN_SCORE=0.1  # Reserved for Phase 3 — not enforced yet
# DECAY_TYPE_OVERRIDES=github_ci_result:7,github_code_blob:14,github_commit:14,conversation:21,session_summary:21,github_issue:30,github_pr:30,jira_issue:30,agent_memory:30,agent_handoff:30,guideline:60,rule:60,architecture_decision:90  # Advanced: per-type half-life overrides

# --- Audit Trail (Foundation) ---
# AUDIT_DIR=.audit  # Advanced: project-local audit directory (default: .audit)

# --- Automated Updates (Foundation) ---
AUTO_UPDATE_ENABLED=true

# --- GitHub Integration (optional) ---
# GITHUB_SYNC_ENABLED=false
# GITHUB_TOKEN=ghp_your_fine_grained_token_here
# GITHUB_REPO=owner/repo
# GITHUB_SYNC_INTERVAL=1800
# GITHUB_BRANCH=main
# GITHUB_CODE_BLOB_ENABLED=true
# GITHUB_CODE_BLOB_MAX_SIZE=102400
# GITHUB_CODE_BLOB_EXCLUDE=node_modules,*.min.js,.git,__pycache__,*.pyc,build,dist,*.egg-info
# GitHub sync security scanning mode: relaxed (PII only), strict (full scan), off (no scan)
SECURITY_SCAN_GITHUB_MODE=relaxed
